version: "3.7"

networks:
  kafka-network:
    driver: bridge

services:
  postgres:
    image: postgres:15.1
    container_name: postgres
    hostname: postgres
    networks:
      - kafka-network
    ports:
      - "5432:5432"
    volumes:
      - ./dbs-init.sql:/docker-entrypoint-initdb.d/dbs-init.sql
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_MULTIPLE_DATABASES=demo

  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - kafka-network
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  broker:
    image: confluentinc/cp-kafka:6.2.0
    container_name: broker
    hostname: broker
    networks:
      - kafka-network
    ports:
      - "29092:29092"
      - "9092:9092"
      - "9101:9101"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://broker:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_CREATE_TOPICS: "my-connect-offsets:1:1"

  kafka-connect:
    image: confluentinc/cp-kafka-connect:6.2.0
    container_name: kafka-connect
    hostname: connect
    networks:
      - kafka-network
    ports:
      - '8083:8083'
    depends_on:
      - broker
      - sftp-server
      - postgres
    volumes:
      - ./connectors:/connectors
    command: sh -c /connectors/start-configuration.sh
    environment:
      ZOOKEEPER_HOSTS: "zookeeper:2181" # env-var for starting script
      CONNECT_BOOTSTRAP_SERVERS: 'broker:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: 'connect'
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: 'connect-group'
      CONNECT_CONFIG_STORAGE_TOPIC: 'my-connect-config'
      CONNECT_OFFSET_STORAGE_TOPIC: 'my-connect-offsets'
      CONNECT_STATUS_STORAGE_TOPIC: 'my-connect-status'
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1" # needed for docker, otherwise they will be created with 3 partitions
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_KEY_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
      CONNECT_VALUE_CONVERTER: 'org.apache.kafka.connect.storage.StringConverter'
      CONNECT_INTERNAL_KEY_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_INTERNAL_VALUE_CONVERTER: 'org.apache.kafka.connect.json.JsonConverter'
      CONNECT_LOG4J_APPENDER_STDOUT_LAYOUT_CONVERSIONPATTERN: "[%d] %p %X{connector.context}%m (%c:%L)%n"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"

  control-center:
    image: confluentinc/cp-enterprise-control-center:6.2.0
    container_name: control-center
    hostname: control-center
    networks:
      - kafka-network
    ports:
      - "9021:9021"
    depends_on:
      - broker
      - kafka-connect
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'broker:29092'
      CONTROL_CENTER_CONNECT_CONNECT-DEFAULT_CLUSTER: 'connect:8083'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_INTERNAL_TOPICS_PARTITIONS: 1
      CONTROL_CENTER_MONITORING_INTERCEPTOR_TOPIC_PARTITIONS: 1
      CONFLUENT_METRICS_TOPIC_REPLICATION: 1
      PORT: 9021

  sftp-server:
    image: atmoz/sftp
    restart: always
    container_name: sftp-server
    hostname: sftp-server
    networks:
      - kafka-network
    ports:
      - "22:22"
    expose:
      - "22"
    volumes:
      - ./sftp:/home/user/sftp
    command:
      - user:pass:1001

  kafka-drop:
    image: obsidiandynamics/kafdrop:3.31.0
    container_name: kafka-drop
    networks:
      - kafka-network
    ports:
      - "9000:9000"
    depends_on:
      - broker
    environment:
      - "KAFKA_BROKERCONNECT=broker:29092"
